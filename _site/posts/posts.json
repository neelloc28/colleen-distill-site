[
  {
    "path": "posts/2021-03-21-post-4/",
    "title": "What Affects Independence Among the Elderly?",
    "description": "We used Survival Analysis to see what factors (such as race, income, and overall health) impact the onset of dependence doing various tasks among a sample of elderly people across the United States. (Preview image source)[https://www.seattletimes.com/life/wellness/study-family-caregivers-for-elderly-need-help-too/]",
    "author": [
      {
        "name": "Colleen Minnihan and Analeidi Barrera",
        "url": {}
      }
    ],
    "date": "2021-03-03",
    "categories": [],
    "contents": "\nHere is the blog post where we discuss our process and interesting findings.\n\n\n\n",
    "preview": "posts/2021-03-21-post-4/elderly.jpg",
    "last_modified": "2021-03-21T15:51:25-05:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-03-20-post-3/",
    "title": "Does Straighter = Safer?",
    "description": "Here I use Causal Inference to investigate if sexual orientation impacts college students' perceived safety in the Twin Cities at nighttime. [(Preview image)](https://www.artsy.net/article/artsy-editorial-rainbow-flag-universal-symbol-gay-rights)",
    "author": [
      {
        "name": "Colleen Minnihan",
        "url": {}
      }
    ],
    "date": "2020-11-22",
    "categories": [],
    "contents": "\nTake a look at this website where I talk about my process and findings.\n\n\n\n",
    "preview": "posts/2021-03-20-post-3/pride-flag.jpeg",
    "last_modified": "2021-03-21T15:35:08-05:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-03-20-post-2/",
    "title": "Employee Attrition: Why do people leave their jobs?",
    "description": "Here, we wanted to see which potential (or current) employees have higher likelihoods of leaving a job without being replaced, and which are more likely to stay. To investigate this question, we used Machine Learning concepts to pick the ideal model and parameters for our dataset.",
    "author": [
      {
        "name": "Colleen, Ikran, Sebastian, and Amritha",
        "url": {}
      }
    ],
    "date": "2020-04-21",
    "categories": [],
    "contents": "\n\n\n\n\nIntroduction\n\nMany people remain at their jobs for a long time, but some people inevitably end up leaving. Wouldn’t it be beneficial to be able to tell which potential (or current) employees have a higher likelihood of leaving the job without being replaced, and which are likely to stay?\nThis knowledge could be used by the employers for good. For example, they could see what factors influence employee attrition that can be changed to better the employee’s experience, such as whether or not the employee works overtime. It could also be used for not so good reasons, if a model predicts that a potential employee is likely to quit, and that leads to them not even being considered for the job.\nWe wanted to explore this more, to see if we could accurately predict whether or not an employee will leave their job. We used Kaggle’s (fictional) attrition dataset, which contains data from 1470 employees. In the original dataset, about 83.9% of employees were replaced, while 16.1% resulted in attrition. These percentages are shown in the plot below.\n\n\nggplot(data = attrition, aes(x=Attrition)) +\n  geom_bar(color = 'blue', fill = 'lightblue') +\n  ggtitle(\"Employee Attrition in Full Dataset\")\n\n\n\n\nThe dataset included 35 variables:\n\n [1] \"Age\"                      \"Attrition\"               \n [3] \"BusinessTravel\"           \"DailyRate\"               \n [5] \"Department\"               \"DistanceFromHome\"        \n [7] \"Education\"                \"EducationField\"          \n [9] \"EmployeeCount\"            \"EmployeeNumber\"          \n[11] \"EnvironmentSatisfaction\"  \"Gender\"                  \n[13] \"HourlyRate\"               \"JobInvolvement\"          \n[15] \"JobLevel\"                 \"JobRole\"                 \n[17] \"JobSatisfaction\"          \"MaritalStatus\"           \n[19] \"MonthlyIncome\"            \"MonthlyRate\"             \n[21] \"NumCompaniesWorked\"       \"Over18\"                  \n[23] \"OverTime\"                 \"PercentSalaryHike\"       \n[25] \"PerformanceRating\"        \"RelationshipSatisfaction\"\n[27] \"StandardHours\"            \"StockOptionLevel\"        \n[29] \"TotalWorkingYears\"        \"TrainingTimesLastYear\"   \n[31] \"WorkLifeBalance\"          \"YearsAtCompany\"          \n[33] \"YearsInCurrentRole\"       \"YearsSinceLastPromotion\" \n[35] \"YearsWithCurrManager\"    \n\n\nData Cleaning\n\nTo clean the data, we recoded the levels of the WorkLifeBalance and EnvironmentSatisfaction variables to be more meaningful to the viewer, rather than just easily-misinterperable numbers. Originally these variables were coded as numbers 1-4, but we refactored them to take on their original values, e.g. “High” or “Good”.\n\nOur hypothesis\n\nWe then tried to brainstorm what variables (out of the 35 in the attrition data) might be important predictors of whether or not an employee will quit their job. We split the data into training and testing, and created exploratory plots of some of the variables using the training dataset. A few variables that we thought would be important were OverTime, YearsAtCompany, Age, WorkLifeBalance, and EnvironmentSatisfaction. The relationships of these variables to Attrition are visualized below.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe first model we built was a logistic regression model using these variables (OverTime, YearsAtCompany, Age, WorkLifeBalance, and EnvironmentSatisfaction) that we initially suspected to have an influence on attrition rates.\n1st model\n\n\nset.seed(253)\n\nattrition_mod1 <- train(\n    Attrition ~ OverTime + YearsAtCompany + Age + WorkLifeBalance + EnvironmentSatisfaction ,\n    data = attrition_train,\n    method = \"glm\",\n    family = \"binomial\",\n    trControl = trainControl(method = \"cv\", number = 5),\n    metric = \"Accuracy\",\n    na.action = na.omit\n)\n\n\n\n\n\nCall:\nNULL\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-1.4023  -0.5910  -0.4175  -0.2728   3.3062  \n\nCoefficients:\n                                   Estimate Std. Error z value\n(Intercept)                         1.50312    0.52390   2.869\nOverTimeYes                         1.46045    0.18813   7.763\nYearsAtCompany                     -0.05950    0.01999  -2.976\nAge                                -0.04962    0.01094  -4.536\nWorkLifeBalanceGood                -0.58249    0.38613  -1.509\nWorkLifeBalanceBetter              -0.90099    0.36450  -2.472\nWorkLifeBalanceBest                -0.60660    0.44014  -1.378\nEnvironmentSatisfactionMedium      -1.10949    0.27721  -4.002\nEnvironmentSatisfactionHigh        -0.99689    0.24513  -4.067\n`EnvironmentSatisfactionVery High` -1.12372    0.24923  -4.509\n                                   Pr(>|z|)    \n(Intercept)                         0.00412 ** \nOverTimeYes                        8.30e-15 ***\nYearsAtCompany                      0.00292 ** \nAge                                5.72e-06 ***\nWorkLifeBalanceGood                 0.13141    \nWorkLifeBalanceBetter               0.01344 *  \nWorkLifeBalanceBest                 0.16814    \nEnvironmentSatisfactionMedium      6.27e-05 ***\nEnvironmentSatisfactionHigh        4.77e-05 ***\n`EnvironmentSatisfactionVery High` 6.52e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 919.16  on 1028  degrees of freedom\nResidual deviance: 787.87  on 1019  degrees of freedom\nAIC: 807.87\n\nNumber of Fisher Scoring iterations: 5\n\nWe can interpret the exponentiated coefficients of this model as multipliers to the odds of an employee leaving resulting in attrition. For example, the exponentiated coefficient on the OverTimeYes variable of 4.308 means that employees who worked overtime have their odds of leaving resulting in attrition multiplied by 4.308 compared to employees who did not work overtime.\n\nModel Evaluation\n\nTo evaluate this model, we looked at the accuracy rate, as well as the sensitivity and specificty. This model had an accuracy rate of 84.9%. This appears good at first glance, but it is very close to the no information rate (the rate at which a correct guess can be made with no information) of the data, which is 83.6%. Additionally, the sensitivity is 14.2% and the specificity is 98.7%. This means that the model is mostly guessing no attrition for every case and getting the actual no attrition cases right almost all the time and the actual attrition cases wrong almost all the time. We want our model to be able to detect attrition, so this isn’t the best model for us.\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  No Yes\n       No  849 145\n       Yes  11  24\n                                         \n               Accuracy : 0.8484         \n                 95% CI : (0.825, 0.8698)\n    No Information Rate : 0.8358         \n    P-Value [Acc > NIR] : 0.1462         \n                                         \n                  Kappa : 0.1896         \n                                         \n Mcnemar's Test P-Value : <2e-16         \n                                         \n            Sensitivity : 0.14201        \n            Specificity : 0.98721        \n         Pos Pred Value : 0.68571        \n         Neg Pred Value : 0.85412        \n             Prevalence : 0.16424        \n         Detection Rate : 0.02332        \n   Detection Prevalence : 0.03401        \n      Balanced Accuracy : 0.56461        \n                                         \n       'Positive' Class : Yes            \n                                         \n\n\n\n# Accuracy rate of 84.9%... BUT it isn't much better than the No Information Rate (predicting these by chance) of 83.6%...\n# we care more about the sensitivity, which is the percentage of correct predictions that people would leave their job out of all of the people who did end up leaving their job\n# sensitivity is .13; therefore, this model does not seem very good\n\n# CV accuracy of 84.5%\nattrition_mod1$results$Accuracy\n\n\n\nOur second model uses Logistic Regression using all variables except Over18 and StandardHours. These two variables only have one factor, so they are meaningless in our model-building.\n2nd Model\n\n\nset.seed(253)\n\n# Perform logistic regression\nattrition_allvars <- train(\n    Attrition ~ . ,\n    data = attrition_train %>% select(-Over18, -StandardHours),\n    method = \"glm\",\n    family = \"binomial\",\n    trControl = trainControl(method = \"cv\", number = 5),\n    metric = \"Accuracy\",\n    na.action = na.omit\n)\n\nsummary(attrition_allvars)\n\n\n\nCall:\nNULL\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-1.6753  -0.4695  -0.2278  -0.0714   3.4297  \n\nCoefficients: (1 not defined because of singularities)\n                                     Estimate Std. Error z value\n(Intercept)                        -1.154e+01  7.312e+02  -0.016\nAge                                -2.164e-02  1.664e-02  -1.300\nBusinessTravelTravel_Frequently     2.180e+00  5.308e-01   4.106\nBusinessTravelTravel_Rarely         1.275e+00  4.993e-01   2.553\nDailyRate                          -7.058e-04  2.801e-04  -2.520\n`DepartmentResearch & Development`  1.441e+01  7.312e+02   0.020\nDepartmentSales                     1.234e+01  7.312e+02   0.017\nDistanceFromHome                    4.932e-02  1.349e-02   3.657\nEducation                          -7.538e-02  1.093e-01  -0.690\n`EducationFieldLife Sciences`      -1.643e+00  1.031e+00  -1.593\nEducationFieldMarketing            -1.399e+00  1.087e+00  -1.287\nEducationFieldMedical              -1.505e+00  1.039e+00  -1.448\nEducationFieldOther                -1.577e+00  1.115e+00  -1.415\n`EducationFieldTechnical Degree`   -4.602e-01  1.041e+00  -0.442\nEmployeeCount                              NA         NA      NA\nEmployeeNumber                     -2.481e-04  1.914e-04  -1.296\nEnvironmentSatisfactionMedium      -1.367e+00  3.427e-01  -3.989\nEnvironmentSatisfactionHigh        -1.241e+00  3.110e-01  -3.991\n`EnvironmentSatisfactionVery High` -1.480e+00  3.140e-01  -4.714\nGenderMale                          5.581e-01  2.308e-01   2.418\nHourlyRate                          5.191e-03  5.615e-03   0.924\nJobInvolvement                     -5.855e-01  1.518e-01  -3.856\nJobLevel                            2.594e-02  3.989e-01   0.065\n`JobRoleHuman Resources`            1.562e+01  7.312e+02   0.021\n`JobRoleLaboratory Technician`      1.256e+00  5.556e-01   2.260\nJobRoleManager                      7.050e-01  9.822e-01   0.718\n`JobRoleManufacturing Director`    -1.729e-01  6.392e-01  -0.270\n`JobRoleResearch Director`         -2.320e+00  1.335e+00  -1.739\n`JobRoleResearch Scientist`         2.811e-01  5.734e-01   0.490\n`JobRoleSales Executive`            3.118e+00  1.399e+00   2.229\n`JobRoleSales Representative`       4.156e+00  1.463e+00   2.842\nJobSatisfaction                    -3.711e-01  1.017e-01  -3.648\nMaritalStatusMarried                3.528e-01  3.316e-01   1.064\nMaritalStatusSingle                 1.333e+00  4.317e-01   3.088\nMonthlyIncome                       7.089e-06  1.033e-04   0.069\nMonthlyRate                        -5.943e-08  1.564e-05  -0.004\nNumCompaniesWorked                  1.562e-01  4.980e-02   3.136\nOverTimeYes                         2.072e+00  2.454e-01   8.446\nPercentSalaryHike                   1.625e-02  4.975e-02   0.327\nPerformanceRating                  -3.353e-02  5.069e-01  -0.066\nRelationshipSatisfaction           -3.011e-01  1.037e-01  -2.903\nStockOptionLevel                   -2.418e-01  2.019e-01  -1.198\nTotalWorkingYears                  -4.195e-02  3.658e-02  -1.147\nTrainingTimesLastYear              -2.087e-01  9.326e-02  -2.237\nWorkLifeBalanceGood                -5.769e-01  4.806e-01  -1.200\nWorkLifeBalanceBetter              -1.289e+00  4.588e-01  -2.810\nWorkLifeBalanceBest                -8.765e-01  5.489e-01  -1.597\nYearsAtCompany                      9.716e-02  4.504e-02   2.157\nYearsInCurrentRole                 -1.444e-01  5.699e-02  -2.534\nYearsSinceLastPromotion             1.297e-01  5.427e-02   2.390\nYearsWithCurrManager               -1.798e-01  5.671e-02  -3.170\n                                   Pr(>|z|)    \n(Intercept)                        0.987410    \nAge                                0.193437    \nBusinessTravelTravel_Frequently    4.02e-05 ***\nBusinessTravelTravel_Rarely        0.010667 *  \nDailyRate                          0.011732 *  \n`DepartmentResearch & Development` 0.984272    \nDepartmentSales                    0.986536    \nDistanceFromHome                   0.000255 ***\nEducation                          0.490339    \n`EducationFieldLife Sciences`      0.111169    \nEducationFieldMarketing            0.197945    \nEducationFieldMedical              0.147641    \nEducationFieldOther                0.157143    \n`EducationFieldTechnical Degree`   0.658385    \nEmployeeCount                            NA    \nEmployeeNumber                     0.194933    \nEnvironmentSatisfactionMedium      6.65e-05 ***\nEnvironmentSatisfactionHigh        6.58e-05 ***\n`EnvironmentSatisfactionVery High` 2.43e-06 ***\nGenderMale                         0.015601 *  \nHourlyRate                         0.355279    \nJobInvolvement                     0.000115 ***\nJobLevel                           0.948156    \n`JobRoleHuman Resources`           0.982959    \n`JobRoleLaboratory Technician`     0.023810 *  \nJobRoleManager                     0.472884    \n`JobRoleManufacturing Director`    0.786830    \n`JobRoleResearch Director`         0.082097 .  \n`JobRoleResearch Scientist`        0.623925    \n`JobRoleSales Executive`           0.025842 *  \n`JobRoleSales Representative`      0.004490 ** \nJobSatisfaction                    0.000265 ***\nMaritalStatusMarried               0.287269    \nMaritalStatusSingle                0.002014 ** \nMonthlyIncome                      0.945273    \nMonthlyRate                        0.996968    \nNumCompaniesWorked                 0.001714 ** \nOverTimeYes                         < 2e-16 ***\nPercentSalaryHike                  0.743877    \nPerformanceRating                  0.947261    \nRelationshipSatisfaction           0.003694 ** \nStockOptionLevel                   0.231003    \nTotalWorkingYears                  0.251447    \nTrainingTimesLastYear              0.025267 *  \nWorkLifeBalanceGood                0.229984    \nWorkLifeBalanceBetter              0.004958 ** \nWorkLifeBalanceBest                0.110300    \nYearsAtCompany                     0.030984 *  \nYearsInCurrentRole                 0.011290 *  \nYearsSinceLastPromotion            0.016843 *  \nYearsWithCurrManager               0.001525 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 919.16  on 1028  degrees of freedom\nResidual deviance: 573.42  on  979  degrees of freedom\nAIC: 673.42\n\nNumber of Fisher Scoring iterations: 15\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  No Yes\n       No  836  82\n       Yes  24  87\n                                          \n               Accuracy : 0.897           \n                 95% CI : (0.8768, 0.9149)\n    No Information Rate : 0.8358          \n    P-Value [Acc > NIR] : 1.313e-08       \n                                          \n                  Kappa : 0.5648          \n                                          \n Mcnemar's Test P-Value : 3.089e-08       \n                                          \n            Sensitivity : 0.51479         \n            Specificity : 0.97209         \n         Pos Pred Value : 0.78378         \n         Neg Pred Value : 0.91068         \n             Prevalence : 0.16424         \n         Detection Rate : 0.08455         \n   Detection Prevalence : 0.10787         \n      Balanced Accuracy : 0.74344         \n                                          \n       'Positive' Class : Yes             \n                                          \n\n\n\n# The CV accuracy of 87.5%.\nattrition_allvars$results$Accuracy\n\n\n\nThis model has a training accuracy of 89.7% and a CV accuracy of 87.9%, an improvement from the previous model. Additionally, the sensitivity of this model is much higher at 51.5%. However, including almost all of the variables makes this model less intuitive. Additionally, it might make the model more prone to overfitting. In order to address this problem, let’s look at what variables are the most crucial to include in this model by making a variable importance plot:\n\n\nvip(attrition_allvars$finalModel, num_features = 30, bar = FALSE)\n\n\n\n\nThe top 5 most important variables in this model are Overtime, EnvironmentSatisfaction, BusinessTravel, JobInvolvement,and DistanceFromHome. Our third model uses logistic regression with these 5 variables.\n3rd model\n\n\nset.seed(253)\n\n\nattrition_bestvars <- train(\n    Attrition ~ OverTime + BusinessTravel + JobInvolvement + DistanceFromHome + EnvironmentSatisfaction  ,\n    data = attrition_train,\n    method = \"glm\",\n    family = \"binomial\",\n    trControl = trainControl(method = \"cv\", number = 5),\n    metric = \"Accuracy\",\n    na.action = na.omit\n)\n\n\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  No Yes\n       No  844 147\n       Yes  16  22\n                                          \n               Accuracy : 0.8416          \n                 95% CI : (0.8178, 0.8634)\n    No Information Rate : 0.8358          \n    P-Value [Acc > NIR] : 0.3244          \n                                          \n                  Kappa : 0.162           \n                                          \n Mcnemar's Test P-Value : <2e-16          \n                                          \n            Sensitivity : 0.13018         \n            Specificity : 0.98140         \n         Pos Pred Value : 0.57895         \n         Neg Pred Value : 0.85166         \n             Prevalence : 0.16424         \n         Detection Rate : 0.02138         \n   Detection Prevalence : 0.03693         \n      Balanced Accuracy : 0.55579         \n                                          \n       'Positive' Class : Yes             \n                                          \n\n\n\n# The CV accuracy is 84.5%.\nattrition_bestvars$results$Accuracy\n\n\n\nThe model ends up having only 84.2% training accuracy, 84.1% CV accuracy, and 13.0% sensitivity, which is similarly poor to our first model. Another method of trying to reduce the number of variables in a model is by using lasso to penalize having lots of variables. For our 4th model, we tried a lasso model to do this and also hopefully get better accuracy and sensitivity rates.\n4th model\n\n\nset.seed(253)\n\nattrition_lasso <- train(\n    Attrition ~ .,\n    data = attrition_train %>% select(-Over18, -StandardHours),\n    method = \"glmnet\",\n    family = \"binomial\",\n    trControl = trainControl(method = \"cv\", number = 5),\n    tuneGrid = data.frame(alpha = 1, \n                          lambda = 10^seq(-4, 0, length = 100)),\n    metric = \"Accuracy\",\n    na.action = na.omit\n)\n\n\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  No Yes\n       No  838  88\n       Yes  22  81\n                                          \n               Accuracy : 0.8931          \n                 95% CI : (0.8726, 0.9113)\n    No Information Rate : 0.8358          \n    P-Value [Acc > NIR] : 1.080e-07       \n                                          \n                  Kappa : 0.5381          \n                                          \n Mcnemar's Test P-Value : 5.736e-10       \n                                          \n            Sensitivity : 0.47929         \n            Specificity : 0.97442         \n         Pos Pred Value : 0.78641         \n         Neg Pred Value : 0.90497         \n             Prevalence : 0.16424         \n         Detection Rate : 0.07872         \n   Detection Prevalence : 0.10010         \n      Balanced Accuracy : 0.72685         \n                                          \n       'Positive' Class : Yes             \n                                          \n  alpha      lambda  Accuracy     Kappa AccuracySD   KappaSD\n1     1 0.001232847 0.8824485 0.4925641 0.02783599 0.1133576\n\n\n\n# The CV accuracy is 88.2% with a lambda value of 0.001232847.    \nattrition_lasso$bestTune$lambda\n\n\n\n\nModel Evaluation\n\nThis model, using the best lambda (of 0.001232847) had an accuracy rate of 89.31%, which is noticeably higher than the No Information Rate. Most importantly for our model, the sensitivity is 47.9%, meaning, for all the people that truly attrite, we predict correctly 47.9% of the time. Ideally, we would want something higher still, but this sensitivity is much better than the sensitivities in our previous models (besides the all-variable one).\nThe plot below of lambda versus Accuracy shows that Model 4 used the lambda value of 0.001232847, because it resulted in the highest accuracy. However, what happens if we make a new LASSO model with a different lambda value?\n\n\n#plot of lambda values versus accuracy\nattrition_lasso$results %>% \n  ggplot(aes(x = lambda, y = Accuracy)) +\n  geom_line() +\n  scale_x_log10() \n\n\n\n\nNow we try another lasso model with a lambda value of 0.0005336699, to see if this results in a better sensitivity, even if it is at the cost of the accuracy lowering a bit.\n5th Model\n\n\nattrition_lasso_best <- train(\n    Attrition ~ .,\n    data = attrition_train %>% select(-Over18, -StandardHours),\n    method = \"glmnet\",\n    family = \"binomial\",\n    trControl = trainControl(method = \"cv\", number = 5),\n    tuneGrid = data.frame(alpha = 1, \n                          lambda = 0.0005336699),\n    metric = \"Accuracy\",\n    na.action = na.omit\n)\n\n\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  No Yes\n       No  838  85\n       Yes  22  84\n                                         \n               Accuracy : 0.896          \n                 95% CI : (0.8757, 0.914)\n    No Information Rate : 0.8358         \n    P-Value [Acc > NIR] : 2.258e-08      \n                                         \n                  Kappa : 0.5545         \n                                         \n Mcnemar's Test P-Value : 2.050e-09      \n                                         \n            Sensitivity : 0.49704        \n            Specificity : 0.97442        \n         Pos Pred Value : 0.79245        \n         Neg Pred Value : 0.90791        \n             Prevalence : 0.16424        \n         Detection Rate : 0.08163        \n   Detection Prevalence : 0.10301        \n      Balanced Accuracy : 0.73573        \n                                         \n       'Positive' Class : Yes            \n                                         \n  alpha       lambda  Accuracy     Kappa AccuracySD   KappaSD\n1     1 0.0005336699 0.8765475 0.4840958 0.02442669 0.1102381\n\nThis model, using the best lambda (of 0.001232847) had a training accuracy rate of 89.6% and CV accuracy rate of 87.3%. The sensitivity also went up to 49.7%. The specificity is at 97.4%, meaning that we predict the people who will remain in their positions almost perfectly. Additionally, 5 coefficients were omitted - DepartmentSales, EmployeeCount, JobLevel, MonthlyIncome, and MonthlyRate. This could potentially help alleviate issues with overfitting on our training data.\nConclusion\nModel\nAccuracy\nSensitivity\nSpecificity\nCV Accuracy\nModel 1: Logistic Regression with Exploratory Variables\n0.8484\n0.14201\n0.98721\n0.8416292\nModel 2: Logistic Regression with All Variables\n0.897\n0.51479\n.97209\n0.8785603\nModel 3: Logistic Regression with Most Important Variables\n0.8416\n0.13018\n0.98140\n0.8406394\nModel 4: LASSO with “Best” Lambda\n0.8931\n0.47929\n0.97442\n0.8824485\nModel 5: LASSO with Different Lambda\n0.896\n0.49704\n0.97442\n0.8726971\nTo pick the final model that we want to use, we need to remember what the goal was of this model-building process: we want to predict who is most likely to attrite. That is, who is most likely to leave their position and not be replaced? The sensitivity will tell us that.The model with the highest sensitivity is Model 2. However, this model may be overfitting to the training data. Model 5 has the second highest sensitivity. We now fit Models 2 and 5 on the testing data to see which is the best:\n\n\n#Model 2\nconfusionMatrix(data = predict(attrition_allvars, newdata = attrition_test, type = \"raw\"), reference = as.factor(attrition_test$Attrition), \n                positive = \"Yes\")\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  No Yes\n       No  357  40\n       Yes  16  28\n                                          \n               Accuracy : 0.873           \n                 95% CI : (0.8383, 0.9026)\n    No Information Rate : 0.8458          \n    P-Value [Acc > NIR] : 0.061980        \n                                          \n                  Kappa : 0.4311          \n                                          \n Mcnemar's Test P-Value : 0.002116        \n                                          \n            Sensitivity : 0.41176         \n            Specificity : 0.95710         \n         Pos Pred Value : 0.63636         \n         Neg Pred Value : 0.89924         \n             Prevalence : 0.15420         \n         Detection Rate : 0.06349         \n   Detection Prevalence : 0.09977         \n      Balanced Accuracy : 0.68443         \n                                          \n       'Positive' Class : Yes             \n                                          \n\n#Model 5\nconfusionMatrix(data = predict(attrition_lasso_best, newdata = attrition_test, type = \"raw\"), reference = as.factor(attrition_test$Attrition), \n                positive = \"Yes\")\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  No Yes\n       No  360  40\n       Yes  13  28\n                                          \n               Accuracy : 0.8798          \n                 95% CI : (0.8458, 0.9087)\n    No Information Rate : 0.8458          \n    P-Value [Acc > NIR] : 0.0251453       \n                                          \n                  Kappa : 0.45            \n                                          \n Mcnemar's Test P-Value : 0.0003551       \n                                          \n            Sensitivity : 0.41176         \n            Specificity : 0.96515         \n         Pos Pred Value : 0.68293         \n         Neg Pred Value : 0.90000         \n             Prevalence : 0.15420         \n         Detection Rate : 0.06349         \n   Detection Prevalence : 0.09297         \n      Balanced Accuracy : 0.68846         \n                                          \n       'Positive' Class : Yes             \n                                          \n\nSurprisingly, their sensitivities are the same! The accuracy on Model 5 is 0.8798 while the accuracy on Model 2 is 0.873, so we can choose Model 5 as our best model for the time being.\n\nOur thoughts\n\nIn the future, we should keep trying to find a model with an even higher sensitivity, because the sensitivity is not “good” in any of these models, and we don’t want to be making many inaccurate predictions about such an important issue. After running the models on the testing data we can conclude that Model 5 (a lasso model fitting all variables with a chosen lambda value) is the “best” model.\n\n\n\n",
    "preview": "posts/2021-03-20-post-2/post-2_files/figure-html5/unnamed-chunk-3-1.png",
    "last_modified": "2021-03-20T20:05:46-05:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-03-19-post-1/",
    "title": "Exploring Metro Transit and Nice Ride Data",
    "description": "Here we looked at transportation data from Metro Transit and Nice Ride bike sharing to see what might impact trends in ridership.  This was my final project for Introduction to Data Science. [(Preview image source)](https://www.metrotransit.org/metro)",
    "author": [
      {
        "name": "Colleen Minnihan, Ellen Graham, Zain Ijaz, Vishal Rana",
        "url": {}
      }
    ],
    "date": "2017-12-06",
    "categories": [],
    "contents": "\nIntroduction\nOur group wanted to know if any relationship exists between Metro Transit Bus Systems and Nice Ride Bikesharing. Through looking at what kinds of information the data gave us, we narrowed down our research to two main questions:\nWhat is the correlation between weather and ridership on Metro Transit and Nice Ride?\nHow do geographical factors relate to Nice Ride and Metro Transit usage?\nFrom there, we took a closer look at each question. While looking at weather, we examined many factors that could influence ridership, such as temperature, precipitation, and snowfall. Through further analysis, we saw that there was no real correlation between precipitation, snowfall, and ridership. Therefore, we focused on temperature, with the sub-question: 1.How does temperature relate to usage? Specifically, we looked at ridership when temperature on a given day in 2016 varied from that area’s average temperature over the last seven years.\nAs for geographical factors, we pruned that broad research question down to: 1. Does distance between bus stops and bike stations correlate with usage? 2. How does Nice Ride usage vary over a day? 3. Does distance relate to usage over a small period of a day? 4. Are usage patterns different in different parts of the city?\nWe were curious if the proximity of a Nice Ride station to a bus stop directly influenced ridership of that Nice Ride station. To gain a deeper understanding, we looked at how Nice Ride usage rose and fell throughout a given day (weekday, Saturday, and Sunday). Lastly, we examined the relationship between proximity of a Nice Ride station to a bus stop and usage of the bike station during five hours of a given day. Initially, we were using three random bus stops for our analysis. We then wondered about two of the most popular Nice Ride stations: one in downtown Minneapolis (likely used for business), and one along Lake Bede Maka Ska (likely used for leisure). Through these more specific research questions, we were able to hypothesize that people combo their transit, meaning they get off a Metro Transit bus and go to a Nice Ride bike station to continue their journey.\nData Collection Process\nInitially, we decided to work with Uber and Lyft data but soon realized that neither of the two were very forthcoming with their data. Our group then started looking for other forms of alternate transit, specifically bike sharing systems within the Twin Cities and eventually found Nice Ride bike sharing data which not only was easily accessible but also was very vast which helped us come up with accurate visualizations and solid conclusions. After obtaining data from Nice Ride, we wanted to know how this form of transit was affected by changes in weather. For that, we looked at various data sources and decided to use weather data from the Minnesota Department of Natural Resources (MN DNR). We chose this specific data because it contained weather information about Minnesota only while other weather data sets contained information pertaining to states other than Minnesota as well and making effective visualizations with the other data sources was not very feasible. Our research question was about metro transit vs. alternate forms of transit and hence, we used Metro Transit data provided to us by Mr. Eric Lind combined with the Nice Ride and MN DNR data to tackle our research topic.\nDatasets we will use\nmetroStops\nData source: Metro Transit Data description: Location of each bus stop (with site ID, city, latitude, longitude, etc.) Data limitations: bus stops that exist from 2014-2017 Data dimensions: 14,919 x 12\nmetroRidership\nData source: Metro Transit\nData description: Gives the day, if it’s a holiday, route number, route type, number of trips, and total number of riders on that day\nData limitations: from January 2014 - October 2017\nData dimensions: 131,078 x 10\nNicerideRidership\nData Source: Nice Ride 2016 data\nData Description: Data contains information about trips: the start and end stations of each trip, the total time it took to complete the journey, and whether the passenger was a casual rider or a member.\nData Limitations: Does not contain information about metro rides in December, January, February, and March. Only has 432283 rows with data in them, the rest are empty and this data has to be cleaned accordingly before use.\nData dimensions: >432,284x8\nNiceRideStops\nData Source: Nice Ride 2016 data\nData Description: Data contains names of Metro Bus Stations, and the exact coordinates of each station (latitude and longitude)\nData Limitations: This dataset contains everything we require to come up with comprehensive visualizations hence, there are no limitations to this data.\nData Dimensions: 202 x 6\nMinneapolisWeather\nData Source: “http://www.dnr.state.mn.us/climate/twin_cities/listings.html”, the Department of Natural Resources has data going back to 1871 on the weather in Minneapolis/St. Paul. All data after 1938 is from MSP airport\nData Description: Gives the date, max temperature, min temperature, amount of percpititaion, amount of snow, and amount of snow on the ground\nData Limitations The specific data we’re using is the weather data between 2010 and 2017. It’s missing the average tempearture for a day, but the min and max are probably enough to work with\nData dimensions: 2884 x 6\n\n\n\n\n\n\nRead in data on MetroTransit\n\n\n\nWeather analysis\n\n\n\n\n\n\n\n\n\nVisualization of how ridership is dependent on temperature of a day and how it depends on divergence from historical temperature on that day.\n\n\n\nWe see that ridership does correlate wtih absolute temperature peaking at around 50 degrees F.\n\n\n\nRidership drops off significantly on days where weather is significantly colder than norms, and is approximately constant for temps above norms.\nDoing same weather analysis with ridership\n\n\n\nLook at how NiceRide ridership correlates to temperature.\n\n\n\nUnsuprisingly, more people ride bikes in warmer weather.\nNow look at how ridership correlates to departure from climate normals.\n\n\n\nPeople ride much less on days with much lower temperatures than normals, and more on days higher than normals.\nGeography and Bike and Bus Ridership\n\n\n\nFirst, let’s visualize where all of the Minneapolis Metro Transit bus stops and Nice Ride bike stations are located.\n\n\n\nHere, we can see the many Metro Transit stations that are in Minneapolis, with a large cluster of them in located in downtown Minneapolis.\n\n\n\nWe can see that there are much fewer Nice Ride stations than Metro Transit bus stops, with most stations clustered in the center of Minneapolis and near parks.\n\n\n\nTo visualize Niceride stations’ distances to bus stops and their ridership.\n\n\n\nNow that we have a basic understanding of where the Minneapolis Metro Transit stop and Nice Ride Stations are located, we wanted to see how distance from a bike station to a bus stop influenced ridership. Each dot on the map represents one Nice Ride station. The sizing of the dots is based on number of total riders over the course of 2016 at that station. The bigger the dot, the more that station was used. The color of the dots represents how close that station was to a bus stop. If the dot color is at the blue end of the spectrum, the Nice Ride station is within 200 meters from a bus stop. If the dot color is orange, it is around 600 meters away from a bus stop. Through this visualization, we can see that the closer a bike station is to a bus stop, the more usage it gets.\n\n\n\n\n\n\n\n\n\nNext, select a set of 3 random bus stations and understand how stations less than 500 meters from these stations change in usage over time.\n\n\n\nVisualize how bike stations near to selected bus stations vary in usage between 3PM and 8PM.\n\n\n\n\n\n#calculates amount of trips the graph represents\nniceRideSampledClose%>%\n   count(site_id)\n\n\n  site_id    n\n1  Stop 1  603\n2  Stop 2 1359\n3  Stop 3  266\n\nWe see spikes and dips in usage that at regular intervals, perhaps indicating a relationship between a bus letting out people and those people using NiceRide.\nFind representative bike station for downtown St. Paul, Minneapolis, and Lake Bde Maka Ska.\n\n\n\nNext, find closest bus stop to these stations.\n\n\n\n\n\n#Gives total number of trips for these two stations in this time period\nniceRideRep%>%\n   count(stationName)\n\n\n        stationName    n\n1 Lake Bde Maka Ska 2888\n2       Minneapolis 3608\n\n\n\n\n",
    "preview": "posts/2021-03-19-post-1/aline-bus.jpg",
    "last_modified": "2021-03-21T15:36:49-05:00",
    "input_file": {}
  }
]
